{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "df = pd.read_csv('../results/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "x_1: 0.8\n",
      "x_2: 0.2\n",
      "x_3: -0.0\n",
      "Best score: 1.073\n",
      "\n",
      "Corresponding standardized metrics:\n",
      "mean_earnings: -1.555\n",
      "passengerless_rate: -0.031\n",
      "todest_time_rate: 0.031\n",
      "earning_per_time: -1.735\n",
      "\n",
      "Corresponding original metrics:\n",
      "mean_earnings: -1.555\n",
      "passengerless_rate: -0.031\n",
      "todest_time_rate: 0.031\n",
      "earning_per_time: -1.735\n"
     ]
    }
   ],
   "source": [
    "# Standardize specified columns across all data\n",
    "columns_to_standardize = ['mean_earnings', 'passengerless_rate', 'todest_time_rate', 'earning_per_time']\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "df = df[['weekend', 'x_1', 'x_2', 'x_3', 'mean_earnings', 'passengerless_rate', 'todest_time_rate', 'earning_per_time']]\n",
    "\n",
    "# Filter for weekday data (weekend == 0)\n",
    "weekday_df = df[df['weekend'] == 0]\n",
    "\n",
    "# Generate all valid combinations of x_1, x_2, x_3\n",
    "valid_combinations = []\n",
    "for x1 in np.arange(0, 1.1, 0.1):\n",
    "    for x2 in np.arange(0, 1.1-x1, 0.1):\n",
    "        x3 = round(1.0 - x1 - x2, 1)  # Round to avoid floating point issues\n",
    "        if 0 <= x3 <= 1:\n",
    "            valid_combinations.append((round(x1, 1), round(x2, 1), x3))\n",
    "\n",
    "def objective(x):\n",
    "    x1, x2, x3 = x\n",
    "    \n",
    "    # Find the row that matches these x values\n",
    "    row = weekday_df[(weekday_df['x_1'] == x1) & \n",
    "                     (weekday_df['x_2'] == x2) & \n",
    "                     (weekday_df['x_3'] == x3)]\n",
    "    \n",
    "    if len(row) == 0:\n",
    "        return -np.inf  # Return a large negative value if no matching row is found\n",
    "    \n",
    "    # Compute a combined score (you can adjust this based on your priorities)\n",
    "    score = row['mean_earnings'].sum() - row['passengerless_rate'].sum() + row['earning_per_time'].sum()\n",
    "    return score  # We want to maximize this score\n",
    "\n",
    "# Perform grid search\n",
    "best_score = -np.inf\n",
    "best_x = None\n",
    "\n",
    "for x in valid_combinations:\n",
    "    score = objective(x)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_x = x\n",
    "\n",
    "# Get the best parameters\n",
    "best_x1, best_x2, best_x3 = best_x\n",
    "\n",
    "# Print the results\n",
    "print(\"Best parameters:\")\n",
    "print(f\"x_1: {best_x1:.1f}\")\n",
    "print(f\"x_2: {best_x2:.1f}\")\n",
    "print(f\"x_3: {best_x3:.1f}\")\n",
    "print(f\"Best score: {best_score:.3f}\")\n",
    "\n",
    "# Find the corresponding row in the dataframe\n",
    "best_row = weekday_df[(weekday_df['x_1'] == best_x1) & \n",
    "                      (weekday_df['x_2'] == best_x2) & \n",
    "                      (weekday_df['x_3'] == best_x3)]\n",
    "\n",
    "if len(best_row) > 0:\n",
    "    print(\"\\nCorresponding standardized metrics:\")\n",
    "    print(f\"mean_earnings: {best_row['mean_earnings'].iloc[0]:.3f}\")\n",
    "    print(f\"passengerless_rate: {best_row['passengerless_rate'].iloc[0]:.3f}\")\n",
    "    print(f\"todest_time_rate: {best_row['todest_time_rate'].iloc[0]:.3f}\")\n",
    "    print(f\"earning_per_time: {best_row['earning_per_time'].iloc[0]:.3f}\")\n",
    "\n",
    "    # Reverse the standardization to get original values\n",
    "    original_values = scaler.inverse_transform(best_row[columns_to_standardize])\n",
    "    \n",
    "    print(\"\\nCorresponding original metrics:\")\n",
    "    for i, col in enumerate(columns_to_standardize):\n",
    "        print(f\"{col}: {original_values[0][i]:.3f}\")\n",
    "else:\n",
    "    print(\"\\nError: No matching row found for the optimized parameters in the dataset.\")\n",
    "    print(\"This should not happen with the discrete optimization approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
